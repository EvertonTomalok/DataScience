{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_portuguese = ['de',\n",
    " 'a',\n",
    " 'o',\n",
    " 'que',\n",
    " 'e',\n",
    " 'do',\n",
    " 'da',\n",
    " 'em',\n",
    " 'um',\n",
    " 'para',\n",
    " 'com',\n",
    " 'não',\n",
    " 'uma',\n",
    " 'os',\n",
    " 'no',\n",
    " 'se',\n",
    " 'na',\n",
    " 'por',\n",
    " 'mais',\n",
    " 'as',\n",
    " 'dos',\n",
    " 'como',\n",
    " 'mas',\n",
    " 'ao',\n",
    " 'ele',\n",
    " 'das',\n",
    " 'à',\n",
    " 'seu',\n",
    " 'sua',\n",
    " 'ou',\n",
    " 'quando',\n",
    " 'muito',\n",
    " 'nos',\n",
    " 'já',\n",
    " 'eu',\n",
    " 'também',\n",
    " 'só',\n",
    " 'pelo',\n",
    " 'pela',\n",
    " 'até',\n",
    " 'isso',\n",
    " 'ela',\n",
    " 'entre',\n",
    " 'depois',\n",
    " 'sem',\n",
    " 'mesmo',\n",
    " 'aos',\n",
    " 'seus',\n",
    " 'quem',\n",
    " 'nas',\n",
    " 'me',\n",
    " 'esse',\n",
    " 'eles',\n",
    " 'você',\n",
    " 'essa',\n",
    " 'num',\n",
    " 'nem',\n",
    " 'suas',\n",
    " 'meu',\n",
    " 'às',\n",
    " 'minha',\n",
    " 'numa',\n",
    " 'pelos',\n",
    " 'elas',\n",
    " 'qual',\n",
    " 'nós',\n",
    " 'lhe',\n",
    " 'deles',\n",
    " 'essas',\n",
    " 'esses',\n",
    " 'pelas',\n",
    " 'este',\n",
    " 'dele',\n",
    " 'tu',\n",
    " 'te',\n",
    " 'vocês',\n",
    " 'vos',\n",
    " 'lhes',\n",
    " 'meus',\n",
    " 'minhas',\n",
    " 'teu',\n",
    " 'tua',\n",
    " 'teus',\n",
    " 'tuas',\n",
    " 'nosso',\n",
    " 'nossa',\n",
    " 'nossos',\n",
    " 'nossas',\n",
    " 'dela',\n",
    " 'delas',\n",
    " 'esta',\n",
    " 'estes',\n",
    " 'estas',\n",
    " 'aquele',\n",
    " 'aquela',\n",
    " 'aqueles',\n",
    " 'aquelas',\n",
    " 'isto',\n",
    " 'aquilo',\n",
    " 'estou',\n",
    " 'está',\n",
    " 'estamos',\n",
    " 'estão',\n",
    " 'estive',\n",
    " 'esteve',\n",
    " 'estivemos',\n",
    " 'estiveram',\n",
    " 'estava',\n",
    " 'estávamos',\n",
    " 'estavam',\n",
    " 'estivera',\n",
    " 'estivéramos',\n",
    " 'esteja',\n",
    " 'estejamos',\n",
    " 'estejam',\n",
    " 'estivesse',\n",
    " 'estivéssemos',\n",
    " 'estivessem',\n",
    " 'estiver',\n",
    " 'estivermos',\n",
    " 'estiverem',\n",
    " 'hei',\n",
    " 'há',\n",
    " 'havemos',\n",
    " 'hão',\n",
    " 'houve',\n",
    " 'houvemos',\n",
    " 'houveram',\n",
    " 'houvera',\n",
    " 'houvéramos',\n",
    " 'haja',\n",
    " 'hajamos',\n",
    " 'hajam',\n",
    " 'houvesse',\n",
    " 'houvéssemos',\n",
    " 'houvessem',\n",
    " 'houver',\n",
    " 'houvermos',\n",
    " 'houverem',\n",
    " 'houverei',\n",
    " 'houverá',\n",
    " 'houveremos',\n",
    " 'houverão',\n",
    " 'houveria',\n",
    " 'houveríamos',\n",
    " 'houveriam',\n",
    " 'sou',\n",
    " 'somos',\n",
    " 'são',\n",
    " 'era',\n",
    " 'éramos',\n",
    " 'eram',\n",
    " 'fui',\n",
    " 'foi',\n",
    " 'fomos',\n",
    " 'foram',\n",
    " 'fora',\n",
    " 'fôramos',\n",
    " 'seja',\n",
    " 'sejamos',\n",
    " 'sejam',\n",
    " 'fosse',\n",
    " 'fôssemos',\n",
    " 'fossem',\n",
    " 'for',\n",
    " 'formos',\n",
    " 'forem',\n",
    " 'serei',\n",
    " 'será',\n",
    " 'seremos',\n",
    " 'serão',\n",
    " 'seria',\n",
    " 'seríamos',\n",
    " 'seriam',\n",
    " 'tenho',\n",
    " 'tem',\n",
    " 'temos',\n",
    " 'tém',\n",
    " 'tinha',\n",
    " 'tínhamos',\n",
    " 'tinham',\n",
    " 'tive',\n",
    " 'teve',\n",
    " 'tivemos',\n",
    " 'tiveram',\n",
    " 'tivera',\n",
    " 'tivéramos',\n",
    " 'tenha',\n",
    " 'tenhamos',\n",
    " 'tenham',\n",
    " 'tivesse',\n",
    " 'tivéssemos',\n",
    " 'tivessem',\n",
    " 'tiver',\n",
    " 'tivermos',\n",
    " 'tiverem',\n",
    " 'terei',\n",
    " 'terá',\n",
    " 'teremos',\n",
    " 'terão',\n",
    " 'teria',\n",
    " 'teríamos',\n",
    " 'teriam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "PATTERN = r\"\"\"\\w+-+\\w+|\\w+|[!'\"#$%&\\*\\+,\\./:;\\?]{1}\"\"\"\n",
    "\n",
    "\n",
    "class TextNLP:\n",
    "    \n",
    "    def __init__(self, text):\n",
    "        assert isinstance(text, str), \"'A classe deve ser inicializada com uma string sendo passada por parâmetro'\"\n",
    "        \n",
    "        if text == '':\n",
    "            raise ValueError('A string passada não pode estar vazia')\n",
    "        \n",
    "        self.text = text\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        \n",
    "        return (match.group() for match in re.finditer(PATTERN, self.text))\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        tokens = self.words\n",
    "        \n",
    "        return \"Texto: %s\\nTokens: %s\\nNum Tokens: %d\" % (self.text, tokens, len(tokens))\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def words(self):\n",
    "            \n",
    "        return list(self.__iter__())\n",
    "    \n",
    "    \n",
    "    def words_preprocessing(self, stop_words_remove=False, punctuation_remove=False):\n",
    "        \n",
    "        tokens = list(self.__iter__())\n",
    "        \n",
    "        if stop_words_remove:\n",
    "            tokens = [tok for tok in tokens if tok not in stop_words_portuguese]\n",
    "        \n",
    "        if punctuation_remove:\n",
    "            tokens = [tok for tok in tokens if tok not in punctuation]\n",
    "            \n",
    "        return tokens\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def sents(self):\n",
    "        doc = nlp(self.text)\n",
    "                \n",
    "        return [sent for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hoje', 'é', 'terça-feira', ',', 'e', 'o', 'lobo', 'é', 'mau', '!', 'E', 'nós', 'também', 'somos', '!', 'Somos', '?', 'Será', 'que', 'somos', '.', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "w = TextNLP('Hoje é terça-feira, e o lobo é mau! E nós também somos! Somos? Será que somos...')\n",
    "print(w.words_preprocessing())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Texto: Hoje é terça-feira, e o lobo é mau! E nós também somos! Somos? Será que somos...\n",
       "Tokens: ['Hoje', 'é', 'terça-feira', ',', 'e', 'o', 'lobo', 'é', 'mau', '!', 'E', 'nós', 'também', 'somos', '!', 'Somos', '?', 'Será', 'que', 'somos', '.', '.', '.']\n",
       "Num Tokens: 23"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hoje',\n",
       " 'é',\n",
       " 'terça-feira',\n",
       " ',',\n",
       " 'e',\n",
       " 'o',\n",
       " 'lobo',\n",
       " 'é',\n",
       " 'mau',\n",
       " '!',\n",
       " 'E',\n",
       " 'nós',\n",
       " 'também',\n",
       " 'somos',\n",
       " '!',\n",
       " 'Somos',\n",
       " '?',\n",
       " 'Será',\n",
       " 'que',\n",
       " 'somos',\n",
       " '.',\n",
       " '.',\n",
       " '.']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoje\n",
      "é\n",
      "terça-feira\n",
      ",\n",
      "e\n",
      "o\n",
      "lobo\n",
      "é\n",
      "mau\n",
      "!\n",
      "E\n",
      "nós\n",
      "também\n",
      "somos\n",
      "!\n",
      "Somos\n",
      "?\n",
      "Será\n",
      "que\n",
      "somos\n",
      ".\n",
      ".\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for item in w.words:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoje é terça-feira, e o lobo é mau!\n",
      "E nós também somos!\n",
      "Somos?\n",
      "Será que somos...\n"
     ]
    }
   ],
   "source": [
    "for sent in w.sents:\n",
    "    print(sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
